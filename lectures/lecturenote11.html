<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
<!--
<script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
<script type="text/javascript">
LatexIT.add('p',true);
</script>
-->

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX","input/MathML","output/SVG", "output/CommonHTML"],
  extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "CHTML-preview.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
  },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js">
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full"></script>

	
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Lecture 12: Bias Variance Tradeoff </title>
<link href="lecturecss.css" rel="stylesheet" type="text/css">

</head>
<body>
<h2> Lecture 11: Bias-Variance Tradeoff </h2>
<div style="float: left">
<a href="lecturenote10.html">previous</a>
</div>
<div style="float: right">
<a href="lecturenote12.html">next</a>
</div>
<div style="margin: 0 auto; width: 100px;"><a href="https://courses.cis.cornell.edu/cs4780/2017sp/">back</a>
</div>
<br><br>

As usual, we are given a dataset $D = \{(\mathbf{x}_1, y_1), \dots, (\mathbf{x}_n,y_n)\}$, drawn i.i.d. from some distribution $P(X,Y)$. Throughout  this lecture we assume a regression setting, i.e.   $y \in \mathbb{R}$.

In this lecture we will decompose the generalization error of a classifier into three rather interpretable terms. Before we do that, let us consider that for any given input $\mathbf{x}$ there might not exist a unique label $y$. For example, if your vector $\mathbf{x}$ describes features of house (e.g. #bedrooms, square footage, ...) and the label $y$ its price, you could imagine two houses with identical description selling for different prices. So for any given feature vector $\mathbf{x}$, there is a distribution over possible labels. We therefore define the following, which will come in useful later on:
<br>
<b>Expected Label</b> (given $\mathbf{x} \in \mathbb{R}^d$): 
\[ 
\bar{y}(\mathbf{x}) = E_{y \vert \mathbf{x}} \left[Y\right] = \int\limits_y y \, \Pr(y \vert \mathbf{x}) \partial y. 
\]
The expected label denotes the label you would expect to obtain, given a feature vector $\mathbf{x}$. 

<br>
Alright, so we draw our training set $D$, consisting of $n$ inputs, i.i.d. from the distribution $P$. As a second step we typically call some machine learning algorithm $\mathcal{A}$ on this data set to learn a hypothesis (aka classifier). Formally, we denote this process as $h_D = \mathcal{A}(D)$.  
<br>
For a given $h_D$, learned on data set $D$ with algorithm $\mathcal{A}$, we can compute the generalization error (as measured in squared loss) as follows:

<br><br>
<b>Expected Test Error</b> (given $h_D$):
<br>
\[
E_{(\mathbf{x},y) \sim P} \left[ \left(h_D (\mathbf{x}) - y \right)^2 \right] = \int\limits_x \! \! \int\limits_y \left( h_D(\mathbf{x}) - y\right)^2 \Pr(\mathbf{x},y) \partial y \partial \mathbf{x}.
\]
Note that one can use other loss functions.
We use squared loss because it has nice mathematical properties, and it is also the most common loss function.
<br>
The previous statement is true for a given training set $D$. However, remember that $D$ itself is drawn from $P^n$, and is therefore a random variable. Further, $h_D$ is a function of $D$, and is therefore also a random variable. And we can of course compute its expectation:

<br><br>
<b>Expected Classifier</b> (given $\mathcal{A}$): 
\[
\bar{h} = E_{D \sim P^n} \left[ h_D \right] = \int\limits_D h_D \Pr(D) \partial D
\]
where $\Pr(D)$ is the probability of drawing $D$ from $P^n$.
Here, $\bar{h}$ is a weighted average over functions. 

<br>
We can also use the fact that $h_D$ is a random variable  to compute the expected test error only given $\mathcal{A}$, taking the expectation also over $D$. 
<br><br>
<b>Expected Test Error</b> (given $\mathcal{A}$):
\begin{equation*}
E_{\substack{(\mathbf{x},y) \sim P\\ D \sim P^n}} \left[\left(h_{D}(\mathbf{x}) - y\right)^{2}\right] = \int_{D} \int_{\mathbf{x}} \int_{y} \left( h_{D}(\mathbf{x}) - y\right)^{2} \mathrm{P}(\mathbf{x},y) \mathrm{P}(D) \partial \mathbf{x} \partial y \partial D
\end{equation*}
To be clear, $D$ is our training points and the $(\mathbf{x},y)$ pairs are the test points.
<br>
We are interested in exactly this expression, because it evaluates the quality of a machine learning algorithm $\mathcal{A}$ with respect to a data distribution $P(X,Y)$. In the following we will show that this expression decomposes into three meaningful terms. 

<h3>Decomposition of Expected Test Error</h3>
\begin{align}
	E_{\mathbf{x},y,D}\left[\left[h_{D}(\mathbf{x}) - y\right]^{2}\right] &= E_{\mathbf{x},y,D}\left[\left[\left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right) + \left(\bar{h}(\mathbf{x}) - y\right)\right]^{2}\right] \nonumber \\
    &= E_{\mathbf{x}, D}\left[(\bar{h}_{D}(\mathbf{x}) - \bar{h}(\mathbf{x}))^{2}\right] + 2 \mathrm{\;} E_{\mathbf{x}, y, D} \left[\left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right)\left(\bar{h}(\mathbf{x}) - y\right)\right] + E_{\mathbf{x}, y} \left[\left(\bar{h}(\mathbf{x}) - y\right)^{2}\right] \label{eq:eq1}
\end{align}

The middle term of the above equation is $0$ as we show below
\begin{align*}
	E_{\mathbf{x}, y, D} \left[\left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right) \left(\bar{h}(\mathbf{x}) - y\right)\right] &= E_{\mathbf{x}, y} \left[E_{D} \left[ h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right] \left(\bar{h}(\mathbf{x}) - y\right) \right] \\
    &= E_{\mathbf{x}, y} \left[ \left( E_{D} \left[ h_{D}(\mathbf{x}) \right] - \bar{h}(\mathbf{x}) \right) \left(\bar{h}(\mathbf{x}) - y \right)\right] \\
    &= E_{\mathbf{x}, y} \left[ \left(\bar{h}(\mathbf{x}) - \bar{h}(\mathbf{x}) \right) \left(\bar{h}(\mathbf{x}) - y \right)\right] \\
    &= E_{\mathbf{x}, y} \left[ 0 \right] \\
    &= 0
\end{align*}

Returning to the earlier expression, we're left with the variance and another term
\begin{equation}
	E_{\mathbf{x}, y, D} \left[ \left( h_{D}(\mathbf{x}) - y \right)^{2} \right] = \underbrace{E_{\mathbf{x}, D} \left[ \left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x}) \right)^{2} \right]}_\mathrm{Variance} + E_{\mathbf{x}, y}\left[ \left( \bar{h}(\mathbf{x}) - y \right)^{2} \right] \label{eq:eq2}
\end{equation}

We can break down the second term in the above equation as follows:
\begin{align}
	E_{\mathbf{x}, y} \left[ \left(\bar{h}(\mathbf{x}) - y \right)^{2}\right] &= E_{\mathbf{x}, y} \left[ \left(\bar{h}(\mathbf{x}) -\bar y(\mathbf{x}) )+(\bar y(\mathbf{x}) - y \right)^{2}\right]  \\
  &=\underbrace{E_{\mathbf{x}, y} \left[\left(\bar{y}(\mathbf{x}) - y\right)^{2}\right]}_\mathrm{Noise} + \underbrace{E_{\mathbf{x}} \left[\left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)^{2}\right]}_\mathrm{Bias^2} + 2 \mathrm{\;} E_{\mathbf{x}, y} \left[ \left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)\left(\bar{y}(\mathbf{x}) - y\right)\right] \label{eq:eq3}
\end{align}

The third term in the equation above is $0$, as we show below
\begin{align*}
	E_{\mathbf{x}, y} \left[\left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)\left(\bar{y}(\mathbf{x}) - y\right)\right] &= E_{\mathbf{x}}\left[E_{y \mid \mathbf{x}} \left[\bar{y}(\mathbf{x}) - y \right] \left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x}) \right) \right] \\
    &= E_{\mathbf{x}} \left[ E_{y \mid \mathbf{x}} \left[ \bar{y}(\mathbf{x}) - y\right] \left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)\right] \\
    &= E_{\mathbf{x}} \left[ \left( \bar{y}(\mathbf{x}) - E_{y \mid \mathbf{x}} \left [ y \right]\right) \left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)\right] \\
    &= E_{\mathbf{x}} \left[ \left( \bar{y}(\mathbf{x}) - \bar{y}(\mathbf{x}) \right) \left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)\right] \\
    &= E_{\mathbf{x}} \left[ 0 \right] \\
    &= 0
\end{align*}

This gives us the decomposition of expected test error as follows
\begin{equation*}
	\underbrace{E_{\mathbf{x}, y, D} \left[\left(h_{D}(\mathbf{x}) - y\right)^{2}\right]}_\mathrm{Expected\;Test\;Error} = \underbrace{E_{\mathbf{x}, D}\left[\left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right)^{2}\right]}_\mathrm{Variance} + \underbrace{E_{\mathbf{x}, y}\left[\left(\bar{y}(\mathbf{x}) - y\right)^{2}\right]}_\mathrm{Noise} + \underbrace{E_{\mathbf{x}}\left[\left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)^{2}\right]}_\mathrm{Bias^2}
\end{equation*}

<b>Variance</b>:
Captures how much your classifier changes if you train on a different training set. How "over-specialized" is your classifier to a particular training set (overfitting)? If we have the best possible model for our training data, how far off are we from the average classifier?
<br><br/>
<b>Bias</b>:
What is the inherent error that you obtain from your classifier even with infinite training data? This is due to your classifier being "biased" to a particular kind of solution (e.g. linear classifier). In other words, bias is inherent to your model.
<br/><br/>
<b>Noise</b>:
How big is the data-intrinsic noise? This error measures ambiguity due to your data distribution and feature representation. You can never beat this, it is an aspect of the data.
<br><br/>
<blockquote>
    <center>
    <img src="images/bias_variance/bullseye.png" width="75.0%" />
	<p>Fig 1: Graphical illustration of bias and variance.<br>
	Source: <a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">http://scott.fortmann-roe.com/docs/BiasVariance.html</a></p>
    </center>
</blockquote>

<blockquote>
    <center>
    <img src="http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png" />
	<p>Fig 2: The variation of Bias and Variance with the model complexity. This is similar to the concept of overfitting and underfitting. More complex models overfit while the simplest models underfit.<br>
	Source: <a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">http://scott.fortmann-roe.com/docs/BiasVariance.html</a></p>
    </center>
</blockquote>
<!-- 
<blockquote>
    <center>
    <img src="images/bias_variance/biasvariance.png" width="75.0%" />
	<p>Fig 1: Decomposition of test error.</p>
    </center>
</blockquote>

<br>

Figure 1 graphically captures the components of the test error that we derived above. 
It is easy to verify from the graph that these components added together form the test error. Important points to notice:
<ul>
<li> Noise is essentially constant.</li>
<li> Bias decreases as our tree grows.</li>
<li> Variance decreases until a certain level of depth, where it then starts increasing again.</li>
</ul>
Let's return to our standard example with two Gaussian distributions.
We can explore how the bias and variance change with respect to the tree depth. 
<blockquote>
    <center>
    <img src="images/bias_variance/biasdata.png" width="45.0%">
	<img src="images/bias_variance/variancedata.png" width="45.0%" />
	<p>Fig 2: The contribution of each data point to the Bias (left) and Variance (right) of a decision
tree with increasing depth.</p>
	<img src="images/bias_variance/nosiedata.png" width="75.0%" />
	<p>Fig 4: The label noise of a data set sampled from two Gaussian distributions.</p>
    </center>
</blockquote>

Figure 2(a) captures the bias of the tree with increasing depth. 
We can see how the bias reduces as more splits are made.
Figure 2(b) also does the same with the variance.
Though it is hard to see, the smallest variance is actually approximately depth 6 or 7, and increases at depths higher than that.
Lastly, figure 4 shows the noise between the two gaussians where they are heavily overlapping.
 -->


</body>
</html>